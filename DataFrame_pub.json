{"paragraphs":[{"text":"%md\n## Dataset/DataFrame\nReadings: \n\n- `Spark - The Definitive Guide` chapter 3 - 10\n- The official document https://spark.apache.org/docs/2.3.3/sql-programming-guide.html","user":"anonymous","dateUpdated":"2019-11-06T08:47:17-0500","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Learning Dataset/DataFrame</h2>\n<p>Readings: </p>\n<ul>\n  <li><code>Spark - The Definitive Guide</code> chapter 3 - 10</li>\n  <li>The official document <a href=\"https://spark.apache.org/docs/2.3.3/sql-programming-guide.html\">https://spark.apache.org/docs/2.3.3/sql-programming-guide.html</a></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1572989441843_-1292437258","id":"20191007-143023_835288946","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19168"},{"text":"%md\n### Creating Dataframes\n#### Creating Dataframes from Scala `Seq`\n\nWe can convert a Sequence of Tuples to a Spark DF.\ne.g. Seq[(String, Double, String, String)] \n\nA tuple corresponds to a DF row.\nA element in a tuple corresponds to a column to a particular row.","user":"anonymous","dateUpdated":"2019-11-06T09:44:48-0500","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Creating Dataframes</h3>\n<h4>Creating Dataframes from Scala <code>Seq</code></h4>\n<p>We can convert a Sequence of Tuples to a Spark DF.<br/>e.g. Seq[(String, Double, String, String)] </p>\n<p>A tuple corresponds to a DF row.<br/>A element in a tuple corresponds to a column to a particular row.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1572989441843_-1141906430","id":"20190519-201210_1157722001","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19169"},{"text":"%md\n#### Scala Implicit Conversions\n\nIn short, you have to `import spark.implicits._` to convert/cast a `Seq[(String, Double, String, String)]` to a Spark `DataFrame`. (e.g. `lineTupleSeq.toDF`)\n\n#####  (Advanced)\nThis is called implicit conversions in Scala. In this case, `spark.implicits.localSeqToDatasetHolder` creates a Dataset from a local Seq.\n\nSpark Scala Docs:\n- <a href=\"https://spark.apache.org/docs/2.3.0/api/scala/index.html#org.apache.spark.sql.SparkSession$implicits$@localSeqToDatasetHolder[T](s:Seq[T])(implicitevidence$7:org.apache.spark.sql.Encoder[T]):org.apache.spark.sql.DatasetHolder[T]\" target=\"_blank\">implicits.localSeqToDatasetHolder</a>\n- <a href=\"http://spark.apache.org/docs/2.3.0/api/scala/index.html#org.apache.spark.sql.DatasetHolder@toDF(colNames:String*):org.apache.spark.sql.DataFrame\" target=\"_blank\">DatasetHolder</a>","user":"anonymous","dateUpdated":"2019-11-05T16:30:41-0500","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Scala Implicit Conversions</h4>\n<p>In short, you have to <code>import spark.implicits._</code> to convert/cast a <code>Seq[(String, Double, String, String)]</code> to a Spark <code>DataFrame</code>. (e.g. <code>lineTupleSeq.toDF</code>)</p>\n<h5>(Advanced)</h5>\n<p>This is called implicit conversions in Scala. In this case, <code>spark.implicits.localSeqToDatasetHolder</code> creates a Dataset from a local Seq.</p>\n<p>Spark Scala Docs:<br/>- <a href=\"https://spark.apache.org/docs/2.3.0/api/scala/index.html#org.apache.spark.sql.SparkSession$implicits$@localSeqToDatasetHolder[T](s:Seq[T])(implicitevidence$7:org.apache.spark.sql.Encoder[T]):org.apache.spark.sql.DatasetHolder[T]\" target=\"_blank\">implicits.localSeqToDatasetHolder</a><br/>- <a href=\"http://spark.apache.org/docs/2.3.0/api/scala/index.html#org.apache.spark.sql.DatasetHolder@toDF(colNames:String*):org.apache.spark.sql.DataFrame\" target=\"_blank\">DatasetHolder</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1572989441844_-109837896","id":"20190520-102917_1809142825","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19170"},{"text":"/**\n * Each line/record/row must be a Tuple\n * e.g.  Tuple(AAPL,110.5,2018-02-01,Apple)\n * \n * Lines are grouped into a Seq\n * List(\n *   (AAPL,110.5,2018-02-01,Apple),\n *   (AMZN,1500.52,2018-02-01,Ammazon.com),\n *   (FB,170.01,2018-02-01,Facebook)\n * )\n */\n \n/**\nusing toDF method\nLimitation: column type and nullable flag cannot be customized. \nimport spark.implicits._ statement can only be run inside of class defination. All\nimports should be at the top of file before class definition, so toDF() encourages bad \nscala coding practices\n\ntoDF() NOT GOOD FOR PRODUCTION GRADE CODE\n*/\nval lineTuple1 = (\"AAPL\",110.5,\"2018-02-01\",\"Apple\")\nval lineTuple2 = (\"AMZN\",1500.52,\"2018-02-01\",\"Ammazon.com\")\nval lineTuple3 = (\"FB\",170.01,\"2018-02-01\",\"Facebook\")\nval lineTuple4 = (\"MSFT\",121.11,\"2018-01-01\",\"Microsoft\")\nval lineTupleSeq = Seq(lineTuple1,lineTuple2,lineTuple3, lineTuple4)\n\n//To use toDF, you must import this (see next section for details)\n//In fact Zeppellin interpreter already imported this for you\nimport spark.implicits._\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types.{StructType, StructField, StringType, IntegerType};\n\nval stockDf = lineTupleSeq.toDF(\"ticker\",\"price\", \"date\", \"companyName\")\nstockDf.printSchema\n\n//SELECT * FROM stock LIMIT 3\nstockDf.show(3)\n\n//SELECT companyName AS company_name, price FROM stock\nstockDf.select(col(\"companyName\").as(\"company_name\"), col(\"price\")).show()\n\n//another example\nval someDF =  Seq((8,\"bat\"), (64,\"mouse\"), (27, \"horse\")).toDF(\"number\", \"word\")\nsomeDF.printSchema\n\n/**\n * createDataFrame()\n *  -full schema customization \n *  -good scala coding practices\n */\n\nval someData1 = Seq(\n                    Row(8,\"bat\"),\n                    Row(64, \"mouse\"),\n                    Row(22,\"horse\")\n                    )\n\nval someSchema = List(StructField(\"number\", IntegerType, true),\n                     StructField(\"word\", StringType, true)\n                     )\n                    \nval someDF1 = spark.createDataFrame(\n    spark.sparkContext.parallelize(someData1),\n    StructType(someSchema)\n    )\n    ","user":"anonymous","dateUpdated":"2019-11-06T10:13:19-0500","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:119: error: object mrpowers is not a member of package com.github\n       import com.github.mrpowers.spark.daria.sql.SparkSessionExt._\n                         ^\n<console>:120: error: value createDF is not a member of org.apache.spark.sql.SparkSession\n       val otherDF = spark.createDF(\n                           ^\n"}]},"apps":[],"jobName":"paragraph_1572989441844_-1675400558","id":"20190519-201416_412351679","dateCreated":"2019-11-05T16:30:41-0500","dateStarted":"2019-11-06T10:12:38-0500","dateFinished":"2019-11-06T10:12:38-0500","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:19171"},{"text":"%md\n### Creating DF from CSV Files","user":"anonymous","dateUpdated":"2019-11-05T16:30:41-0500","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Creating DF from CSV Files</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1572989441844_596016155","id":"20190520-104920_1833330750","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19172"},{"text":"%md\n","user":"anonymous","dateUpdated":"2019-11-06T08:40:58-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573047658118_-1395512109","id":"20191106-084058_1406496563","dateCreated":"2019-11-06T08:40:58-0500","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:19173"},{"text":"//Read CSV file to df\n//local or hdfs path\nval path = \"/Users/gursimran/Downloads/online-retail-dataset.csv\"\n\n//spark.read is able to handle csv formats\nval retailDf = spark.read.format(\"csv\")\n    .option(\"header\", \"true\")\n    .option(\"inferSchema\", \"true\")\n    .load(path)\n\nretailDf.printSchema\nretailDf.show(3)\nretailDf.show(3,false)","user":"anonymous","dateUpdated":"2019-11-06T10:14:38-0500","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- InvoiceNo: string (nullable = true)\n |-- StockCode: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- InvoiceDate: string (nullable = true)\n |-- UnitPrice: double (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- Country: string (nullable = true)\n\n+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|\n+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\nonly showing top 3 rows\n\n+---------+---------+----------------------------------+--------+--------------+---------+----------+--------------+\n|InvoiceNo|StockCode|Description                       |Quantity|InvoiceDate   |UnitPrice|CustomerID|Country       |\n+---------+---------+----------------------------------+--------+--------------+---------+----------+--------------+\n|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER|6       |12/1/2010 8:26|2.55     |17850     |United Kingdom|\n|536365   |71053    |WHITE METAL LANTERN               |6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER    |8       |12/1/2010 8:26|2.75     |17850     |United Kingdom|\n+---------+---------+----------------------------------+--------+--------------+---------+----------+--------------+\nonly showing top 3 rows\n\npath: String = /Users/gursimran/Downloads/online-retail-dataset.csv\nretailDf: org.apache.spark.sql.DataFrame = [InvoiceNo: string, StockCode: string ... 6 more fields]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.78.7:4040/jobs/job?id=0","http://192.168.78.7:4040/jobs/job?id=1","http://192.168.78.7:4040/jobs/job?id=2","http://192.168.78.7:4040/jobs/job?id=3"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1572989441844_1248385010","id":"20190520-095229_630927102","dateCreated":"2019-11-05T16:30:41-0500","dateStarted":"2019-11-06T10:14:38-0500","dateFinished":"2019-11-06T10:14:41-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19174"},{"text":"import org.apache.spark.sql\n\nretailDf.printSchema\n\nval retailCastDf = retailDf.withColumn(\"InvoiceDate\", col(\"InvoiceDate\").cast(\"timestamp\"))\nretailCastDf.printSchema         \n","user":"anonymous","dateUpdated":"2019-11-06T10:46:58-0500","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- InvoiceNo: string (nullable = true)\n |-- StockCode: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- InvoiceDate: string (nullable = true)\n |-- UnitPrice: double (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- Country: string (nullable = true)\n\nroot\n |-- InvoiceNo: string (nullable = true)\n |-- StockCode: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- InvoiceDate: timestamp (nullable = true)\n |-- UnitPrice: double (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- Country: string (nullable = true)\n\nimport org.apache.spark.sql\nretailCastDf: org.apache.spark.sql.DataFrame = [InvoiceNo: string, StockCode: string ... 6 more fields]\n"}]},"apps":[],"jobName":"paragraph_1572989441844_-1923215628","id":"20190520-085947_2007764287","dateCreated":"2019-11-05T16:30:41-0500","dateStarted":"2019-11-06T10:46:58-0500","dateFinished":"2019-11-06T10:46:58-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19175"},{"text":"\n\n//Cache DF in memory since it will be accessed frequently\nretailCastDf.cache","user":"anonymous","dateUpdated":"2019-11-06T10:47:08-0500","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res6: retailCastDf.type = [InvoiceNo: string, StockCode: string ... 6 more fields]\n"}]},"apps":[],"jobName":"paragraph_1572989441845_-1734895012","id":"20190519-215300_721200493","dateCreated":"2019-11-05T16:30:41-0500","dateStarted":"2019-11-06T10:47:08-0500","dateFinished":"2019-11-06T10:47:08-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19176"},{"text":"%md\n### DataFrame SELECT\nImplement the following SQL queries using dataframe. Compare different select syntax.\n\n```sql\nSELECT *\nFROM retail\nLIMIT 3\n\nSELECT InvoiceNo\nFROM retail\n\nSELECT InvoiceNo as invoiceNo\nFROM retail\n\nSELECT max(UnitPrice) as max_unit_price\nFROM retail\n```","user":"anonymous","dateUpdated":"2019-11-05T16:30:41-0500","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>DataFrame SELECT</h3>\n<p>Implement the following SQL queries using dataframe. Compare different select syntax.</p>\n<pre><code class=\"sql\">SELECT *\nFROM retail\nLIMIT 3\n\nSELECT InvoiceNo\nFROM retail\n\nSELECT InvoiceNo as invoiceNo\nFROM retail\n\nSELECT max(UnitPrice) as max_unit_price\nFROM retail\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1572989441845_756554374","id":"20190519-221054_1925024171","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19177"},{"text":"//SELECT * from retail limit 3;\nretailCastDf.show(3)\nimport org.apache.spark.sql.functions._\n//select InvoiceNo,CustomerID,Country from retail limit 1;\nretailCastDf.select(\"InvoiceNo\").show(1)\n\n//Different ways of select \nretailCastDf.select($\"InvoiceNo\").show(1)\nretailCastDf.select('InvoiceNo).show(1)\nretailCastDf.select(col(\"InvoiceNo\")).show(1)\nretailCastDf.select(retailCastDf.col(\"InvoiceNo\")).show(1)\nretailCastDf.select(expr(\"InvoiceNo\")).show(1)\n\n//ERROR: cannot mix \n//retailCastDf.select($\"InvoiceNo\", \"StockCode\").show(1)\n\n//expr or selectExpr is most powerful and close to SQL syntax\n//SELECT InvoiceNo as invoiceId from retail limit 1;\nretailCastDf.select(expr(\"InvoiceNo as invoiceId\")).show(1)\nretailCastDf.selectExpr(\"InvoiceNo as invoiceId\").show(1)\n\n//SELECT * from retail limit 1;\nretailCastDf.selectExpr(\"*\").show(1)\n\n//select max(UnitPrice) as maxUnitPrice from retail\nretailCastDf.selectExpr(\"max(UnitPrice) as maxUnitPrice\").show \n","user":"anonymous","dateUpdated":"2019-11-06T10:50:07-0500","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|       null|     2.55|     17850|United Kingdom|\n|   536365|    71053| WHITE METAL LANTERN|       6|       null|     3.39|     17850|United Kingdom|\n|   536365|   84406B|CREAM CUPID HEART...|       8|       null|     2.75|     17850|United Kingdom|\n+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\nonly showing top 3 rows\n\n+---------+\n|InvoiceNo|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|InvoiceNo|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|InvoiceNo|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|InvoiceNo|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|InvoiceNo|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|InvoiceNo|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|invoiceId|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|invoiceId|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|       null|     2.55|     17850|United Kingdom|\n+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\nonly showing top 1 row\n\n+------------+\n|maxUnitPrice|\n+------------+\n|     38970.0|\n+------------+\n\nimport org.apache.spark.sql.functions._\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.78.7:4040/jobs/job?id=4","http://192.168.78.7:4040/jobs/job?id=5","http://192.168.78.7:4040/jobs/job?id=6","http://192.168.78.7:4040/jobs/job?id=7","http://192.168.78.7:4040/jobs/job?id=8","http://192.168.78.7:4040/jobs/job?id=9","http://192.168.78.7:4040/jobs/job?id=10","http://192.168.78.7:4040/jobs/job?id=11","http://192.168.78.7:4040/jobs/job?id=12","http://192.168.78.7:4040/jobs/job?id=13","http://192.168.78.7:4040/jobs/job?id=14"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1572989441845_803661199","id":"20190519-211701_1956303781","dateCreated":"2019-11-05T16:30:41-0500","dateStarted":"2019-11-06T10:50:07-0500","dateFinished":"2019-11-06T10:50:12-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19178"},{"text":"//changing column name in df\nval newRetailDf = retailCastDf.selectExpr(\"InvoiceNo as invoiceId\").show()\n","user":"anonymous","dateUpdated":"2019-11-06T11:17:19-0500","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+\n|invoiceId|\n+---------+\n|   536365|\n|   536365|\n|   536365|\n|   536365|\n|   536365|\n|   536365|\n|   536365|\n|   536366|\n|   536366|\n|   536367|\n|   536367|\n|   536367|\n|   536367|\n|   536367|\n|   536367|\n|   536367|\n|   536367|\n|   536367|\n|   536367|\n|   536367|\n+---------+\nonly showing top 20 rows\n\nnewRetailDf: Unit = ()\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.78.7:4040/jobs/job?id=17"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1572989441845_-1085045448","id":"20190519-221114_648626738","dateCreated":"2019-11-05T16:30:41-0500","dateStarted":"2019-11-06T11:15:00-0500","dateFinished":"2019-11-06T11:15:00-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19179"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573059078320_309479360","id":"20191106-115118_929385620","dateCreated":"2019-11-06T11:51:18-0500","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:19180"},{"text":"//filtering rows based on values of a column\n\nval newdf = retailCastDf.filter($\"InvoiceNo\" === 536365).show()\nretailCastDf.show()","user":"anonymous","dateUpdated":"2019-11-06T11:51:40-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|       null|     2.55|     17850|United Kingdom|\n|   536365|    71053| WHITE METAL LANTERN|       6|       null|     3.39|     17850|United Kingdom|\n|   536365|   84406B|CREAM CUPID HEART...|       8|       null|     2.75|     17850|United Kingdom|\n|   536365|   84029G|KNITTED UNION FLA...|       6|       null|     3.39|     17850|United Kingdom|\n|   536365|   84029E|RED WOOLLY HOTTIE...|       6|       null|     3.39|     17850|United Kingdom|\n|   536365|    22752|SET 7 BABUSHKA NE...|       2|       null|     7.65|     17850|United Kingdom|\n|   536365|    21730|GLASS STAR FROSTE...|       6|       null|     4.25|     17850|United Kingdom|\n+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n\n+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|       null|     2.55|     17850|United Kingdom|\n|   536365|    71053| WHITE METAL LANTERN|       6|       null|     3.39|     17850|United Kingdom|\n|   536365|   84406B|CREAM CUPID HEART...|       8|       null|     2.75|     17850|United Kingdom|\n|   536365|   84029G|KNITTED UNION FLA...|       6|       null|     3.39|     17850|United Kingdom|\n|   536365|   84029E|RED WOOLLY HOTTIE...|       6|       null|     3.39|     17850|United Kingdom|\n|   536365|    22752|SET 7 BABUSHKA NE...|       2|       null|     7.65|     17850|United Kingdom|\n|   536365|    21730|GLASS STAR FROSTE...|       6|       null|     4.25|     17850|United Kingdom|\n|   536366|    22633|HAND WARMER UNION...|       6|       null|     1.85|     17850|United Kingdom|\n|   536366|    22632|HAND WARMER RED P...|       6|       null|     1.85|     17850|United Kingdom|\n|   536367|    84879|ASSORTED COLOUR B...|      32|       null|     1.69|     13047|United Kingdom|\n|   536367|    22745|POPPY'S PLAYHOUSE...|       6|       null|      2.1|     13047|United Kingdom|\n|   536367|    22748|POPPY'S PLAYHOUSE...|       6|       null|      2.1|     13047|United Kingdom|\n|   536367|    22749|FELTCRAFT PRINCES...|       8|       null|     3.75|     13047|United Kingdom|\n|   536367|    22310|IVORY KNITTED MUG...|       6|       null|     1.65|     13047|United Kingdom|\n|   536367|    84969|BOX OF 6 ASSORTED...|       6|       null|     4.25|     13047|United Kingdom|\n|   536367|    22623|BOX OF VINTAGE JI...|       3|       null|     4.95|     13047|United Kingdom|\n|   536367|    22622|BOX OF VINTAGE AL...|       2|       null|     9.95|     13047|United Kingdom|\n|   536367|    21754|HOME BUILDING BLO...|       3|       null|     5.95|     13047|United Kingdom|\n|   536367|    21755|LOVE BUILDING BLO...|       3|       null|     5.95|     13047|United Kingdom|\n|   536367|    21777|RECIPE BOX WITH M...|       4|       null|     7.95|     13047|United Kingdom|\n+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\nonly showing top 20 rows\n\nnewdf: Unit = ()\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.78.7:4040/jobs/job?id=29","http://192.168.78.7:4040/jobs/job?id=30"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1573055755777_593443416","id":"20191106-105555_1060986763","dateCreated":"2019-11-06T10:55:55-0500","dateStarted":"2019-11-06T11:51:40-0500","dateFinished":"2019-11-06T11:51:41-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19181"},{"text":"%md\n\n### DF Exercises\n#### Spark SQL temp view\nFor the following DF exercises, instead of jumping right into DF solutions, you can write `sql` solutions and verify with Spark SQL Temp Views.","user":"anonymous","dateUpdated":"2019-11-06T11:16:05-0500","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>DF Exercises</h3>\n<h4>Spark SQL temp view</h4>\n<p>For the following DF exercises, instead of jumping right into DF solutions, you can write <code>sql</code> solutions and verify with Spark SQL Temp Views.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1572989441847_-1942314504","id":"20190520-123428_698724288","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19182"},{"text":"","user":"anonymous","dateUpdated":"2019-11-05T16:30:41-0500","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|\n|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n|   536365|    22752|SET 7 BABUSHKA NE...|       2|12/1/2010 8:26|     7.65|     17850|United Kingdom|\n|   536365|    21730|GLASS STAR FROSTE...|       6|12/1/2010 8:26|     4.25|     17850|United Kingdom|\n+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n\n"}]},"apps":[],"jobName":"paragraph_1572989441847_382445546","id":"20190520-142038_1683726413","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19183"},{"text":"%md\n#### Q1: Find the top N largest invoices by the amount (`Quantity * UnitPrice`)\n\nNote: `InvoiceNo` will appear in multiple rows. <br>(e.g. a receipt can have multiple items on it.)\n\n**Sample output**\n```bash\n+---------+------------------+\n|InvoiceNo|            Amount|\n+---------+------------------+\n|   581483|          168469.6|\n|   541431|           77183.6|\n|   574941| 52940.93999999999|\n|   576365|50653.909999999996|\n|   556444|           38970.0|\n+---------+------------------+\n```","user":"anonymous","dateUpdated":"2019-11-06T11:06:06-0500","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Q1: Find the top N largest invoices by the amount (<code>Quantity * UnitPrice</code>)</h4>\n<p>Note: <code>InvoiceNo</code> will appear in multiple rows. <br>(e.g. a receipt can have multiple items on it.)</p>\n<p><strong>Sample output</strong></p>\n<pre><code class=\"bash\">+---------+------------------+\n|InvoiceNo|            Amount|\n+---------+------------------+\n|   581483|          168469.6|\n|   541431|           77183.6|\n|   574941| 52940.93999999999|\n|   576365|50653.909999999996|\n|   556444|           38970.0|\n+---------+------------------+\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1572989441847_466225031","id":"20190520-133812_405266917","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19184"},{"text":"// spark sql solution\nval invoiceData = retailDf.createOrReplaceTempView(\"retailDfView\")\nval invoices = spark.sql(\"SELECT InvoiceNo, Quantity*UnitPrice AS Amount FROM retailDfView\").orderBy($\"Amount\".desc).show(5)","user":"anonymous","dateUpdated":"2019-11-06T12:52:57-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+--------+\n|InvoiceNo|  Amount|\n+---------+--------+\n|   581483|168469.6|\n|   541431| 77183.6|\n|   556444| 38970.0|\n|   537632|13541.33|\n|  A563185|11062.06|\n+---------+--------+\nonly showing top 5 rows\n\ninvoiceData: Unit = ()\ninvoices: Unit = ()\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.78.7:4040/jobs/job?id=49"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1573057658656_-256549815","id":"20191106-112738_978193753","dateCreated":"2019-11-06T11:27:38-0500","dateStarted":"2019-11-06T12:40:48-0500","dateFinished":"2019-11-06T12:40:49-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19185"},{"text":"//dataframe solution\n\n\nval retDf = retailDf.selectExpr(\"InvoiceNo\",\"quantity*UnitPrice AS Amount\").orderBy(col(\"Amount\").desc).show(5)","user":"anonymous","dateUpdated":"2019-11-06T15:44:49-0500","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+--------+\n|InvoiceNo|  Amount|\n+---------+--------+\n|   581483|168469.6|\n|   541431| 77183.6|\n|   556444| 38970.0|\n|   537632|13541.33|\n|  A563185|11062.06|\n+---------+--------+\nonly showing top 5 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.78.7:4040/jobs/job?id=55"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1572989441847_-2132316408","id":"20190519-215312_1016690251","dateCreated":"2019-11-05T16:30:41-0500","dateStarted":"2019-11-06T13:03:16-0500","dateFinished":"2019-11-06T13:03:17-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19186"},{"user":"anonymous","dateUpdated":"2019-11-05T16:30:41-0500","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1572989441847_1550417185","id":"20191007-145909_914572499","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19187"},{"text":"%md\n#### Q2: Find the top N largest invoices by the amount and show receipt details\n\n```\n+---------+------------------+-------------------+----------+--------------+\n|InvoiceNo|            Amount|        InvoiceDate|CustomerID|       Country|\n+---------+------------------+-------------------+----------+--------------+\n|   581483|          168469.6|2011-12-09 09:15:00|     16446|United Kingdom|\n|   541431|           77183.6|2011-01-18 10:01:00|     12346|United Kingdom|\n|   574941| 52940.93999999999|2011-11-07 17:42:00|      null|United Kingdom|\n|   576365|50653.909999999996|2011-11-14 17:55:00|      null|United Kingdom|\n|   556444|           38970.0|2011-06-10 15:28:00|     15098|United Kingdom|\n+---------+------------------+-------------------+----------+--------------+\n```","user":"anonymous","dateUpdated":"2019-11-06T12:41:02-0500","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Q2: Find the top N largest invoices by the amount and show receipt details</h4>\n<pre><code>+---------+------------------+-------------------+----------+--------------+\n|InvoiceNo|            Amount|        InvoiceDate|CustomerID|       Country|\n+---------+------------------+-------------------+----------+--------------+\n|   581483|          168469.6|2011-12-09 09:15:00|     16446|United Kingdom|\n|   541431|           77183.6|2011-01-18 10:01:00|     12346|United Kingdom|\n|   574941| 52940.93999999999|2011-11-07 17:42:00|      null|United Kingdom|\n|   576365|50653.909999999996|2011-11-14 17:55:00|      null|United Kingdom|\n|   556444|           38970.0|2011-06-10 15:28:00|     15098|United Kingdom|\n+---------+------------------+-------------------+----------+--------------+\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1572989441847_1189318219","id":"20190520-124355_215736883","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19188"},{"text":"\n\nretailDf.selectExpr(\"InvoiceNo\",\"quantity*UnitPrice AS Amount\", \"InvoiceDate\", \"CustomerID\",\"Country\").orderBy(col(\"Amount\").desc).show(5)","user":"anonymous","dateUpdated":"2019-11-06T13:04:58-0500","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+--------+---------------+----------+--------------+\n|InvoiceNo|  Amount|    InvoiceDate|CustomerID|       Country|\n+---------+--------+---------------+----------+--------------+\n|   581483|168469.6| 12/9/2011 9:15|     16446|United Kingdom|\n|   541431| 77183.6|1/18/2011 10:01|     12346|United Kingdom|\n|   556444| 38970.0|6/10/2011 15:28|     15098|United Kingdom|\n|   537632|13541.33|12/7/2010 15:08|      null|United Kingdom|\n|  A563185|11062.06|8/12/2011 14:50|      null|United Kingdom|\n+---------+--------+---------------+----------+--------------+\nonly showing top 5 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.78.7:4040/jobs/job?id=56"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1572989441848_459978942","id":"20190520-122626_1736024345","dateCreated":"2019-11-05T16:30:41-0500","dateStarted":"2019-11-06T13:04:58-0500","dateFinished":"2019-11-06T13:04:59-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19189"},{"text":"%md\n#### Q3: For each country, find the top N largest invoices by the amount and show receipt details\n\nUse `Window functions` and `rank()` function\n\nReadings:\n- https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html\n- https://stackoverflow.com/questions/42966590/how-do-we-rank-dataframe\n- http://blog.madhukaraphatak.com/introduction-to-spark-two-part-5/\n- `Spark The Definitive Guide - page 134 - Windows Function`\n\nsqlContext.sql(\"SELECT accountNumber,assetValue, RANK() OVER (partition by accountNumber ORDER BY assetValue desc) AS rank FROM df\").show\n```\n+---------+------------------+-------------------+----------+---------+\n|InvoiceNo|            amount|        InvoiceDate|CustomerID|  Country|\n+---------+------------------+-------------------+----------+---------+\n|   571318| 5296.960000000001|2011-10-17 10:50:00|     17404|   Sweden|\n|   546530| 4400.280000000001|2011-03-14 13:25:00|     17404|   Sweden|\n|   571751|6068.0599999999995|2011-10-19 11:18:00|     12744|Singapore|\n|   548813|4037.7700000000004|2011-04-04 13:03:00|     12744|Singapore|\n|   552978| 9341.260000000004|2011-05-12 14:46:00|     12590|  Germany|\n|   564856|4257.0599999999995|2011-08-31 09:11:00|     12477|  Germany|\n|   571035|1002.3099999999998|2011-10-13 12:50:00|     12446|      RSA|\n|   573153| 8895.760000000004|2011-10-28 07:39:00|     12678|   France|\n|   570672| 4279.710000000004|2011-10-11 14:52:00|     12536|   France|\n|   541932|           2661.24|2011-01-24 11:39:00|     14439|   Greece|\n+---------+------------------+-------------------+----------+---------+\n```\ndf.withColumn(\"rank\", row_number().over(Window.partitionBy($\"accountNumber\").orderBy($\"assetValue\".desc))).show\n<br>\n<br>\n################ spoiler alert ################\n**Hints**:\n- At high level, you need to create a new column which indicates amount rank by country\n  - Use `Windows` function which partition by (\"Country\") and order by amount\n  - User `Rank()` function create a new `rank` column for each row\n  - filter out rows where `rank < 2`","user":"anonymous","dateUpdated":"2019-11-06T16:32:27-0500","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Q3: For each country, find the top N largest invoices by the amount and show receipt details</h4>\n<p>Use <code>Window functions</code> and <code>rank()</code> function</p>\n<p>Readings:<br/>- <a href=\"https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html\">https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html</a><br/>- <a href=\"https://stackoverflow.com/questions/42966590/how-do-we-rank-dataframe\">https://stackoverflow.com/questions/42966590/how-do-we-rank-dataframe</a><br/>- <a href=\"http://blog.madhukaraphatak.com/introduction-to-spark-two-part-5/\">http://blog.madhukaraphatak.com/introduction-to-spark-two-part-5/</a><br/>- <code>Spark The Definitive Guide - page 134 - Windows Function</code></p>\n<pre><code>+---------+------------------+-------------------+----------+---------+\n|InvoiceNo|            amount|        InvoiceDate|CustomerID|  Country|\n+---------+------------------+-------------------+----------+---------+\n|   571318| 5296.960000000001|2011-10-17 10:50:00|     17404|   Sweden|\n|   546530| 4400.280000000001|2011-03-14 13:25:00|     17404|   Sweden|\n|   571751|6068.0599999999995|2011-10-19 11:18:00|     12744|Singapore|\n|   548813|4037.7700000000004|2011-04-04 13:03:00|     12744|Singapore|\n|   552978| 9341.260000000004|2011-05-12 14:46:00|     12590|  Germany|\n|   564856|4257.0599999999995|2011-08-31 09:11:00|     12477|  Germany|\n|   571035|1002.3099999999998|2011-10-13 12:50:00|     12446|      RSA|\n|   573153| 8895.760000000004|2011-10-28 07:39:00|     12678|   France|\n|   570672| 4279.710000000004|2011-10-11 14:52:00|     12536|   France|\n|   541932|           2661.24|2011-01-24 11:39:00|     14439|   Greece|\n+---------+------------------+-------------------+----------+---------+\n</code></pre>\n<br>\n<br>\n<p>################ spoiler alert ################<br/><strong>Hints</strong>:<br/>- At high level, you need to create a new column which indicates amount rank by country<br/> - Use <code>Windows</code> function which partition by (&ldquo;Country&rdquo;) and order by amount<br/> - User <code>Rank()</code> function create a new <code>rank</code> column for each row<br/> - filter out rows where <code>rank &gt; 2</code></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1572989441848_-685320005","id":"20190520-150543_915955507","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19190"},{"text":"%md\n","user":"anonymous","dateUpdated":"2019-11-06T15:05:54-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573070754935_-2043277946","id":"20191106-150554_660144918","dateCreated":"2019-11-06T15:05:54-0500","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:19191"},{"text":"import org.apache.spark.sql.expressions.Window\nimport org.apache.spark.sql.functions.row_number\nimport spark.implicits._\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types.{StructType, StructField, StringType, IntegerType};\n\nval retDf1 = retailDf.selectExpr(\"InvoiceNo\",\"quantity*UnitPrice AS Amount\", \"Country\")\n\nval windowSpec = Window\n                .partitionBy(\"Country\")\n                .orderBy(col(\"Amount\").desc)\n\nval rankedDf = retDf1.withColumn(\"rank\", row_number().over(Window.partitionBy(\"Country\").orderBy($\"Amount\".desc))).filter(\"rank<=2\")\n\nval printDf = rankedDf.selectExpr(\"InvoiceNo\", \"Amount\", \"Country\").show()","user":"anonymous","dateUpdated":"2019-11-06T15:59:56-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+------------------+------------------+\n|InvoiceNo|            Amount|           Country|\n+---------+------------------+------------------+\n|   538848|            1188.0|            Sweden|\n|   566494|             792.0|            Sweden|\n|   571751|           3949.32|         Singapore|\n|   548813|           2382.92|         Singapore|\n|   569640|             876.0|           Germany|\n|   581179|             700.8|           Germany|\n|   571035|             38.25|               RSA|\n|   571035|              29.9|               RSA|\n|   573077|           4161.06|            France|\n|   573080|           4161.06|            France|\n|   541932|             175.2|            Greece|\n|   541932|            135.84|            Greece|\n|   560783|              60.0|European Community|\n|   560783|              51.0|European Community|\n|   566076|             165.0|           Belgium|\n|   577180|157.92000000000002|           Belgium|\n|   545336|             551.2|           Finland|\n|   548363|             400.0|           Finland|\n|   576897|             455.0|             Malta|\n|   555931|             160.0|             Malta|\n+---------+------------------+------------------+\nonly showing top 20 rows\n\nimport org.apache.spark.sql.expressions.Window\nimport org.apache.spark.sql.functions.row_number\nimport spark.implicits._\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types.{StructType, StructField, StringType, IntegerType}\nretDf1: org.apache.spark.sql.DataFrame = [InvoiceNo: string, Amount: double ... 1 more field]\nwindowSpec: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@5c5bfe2f\nrankedDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [InvoiceNo: string, Amount: double ... 2 more fields]\nprintDf: Unit = ()\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.78.7:4040/jobs/job?id=93","http://192.168.78.7:4040/jobs/job?id=94","http://192.168.78.7:4040/jobs/job?id=95","http://192.168.78.7:4040/jobs/job?id=96"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1573068272623_1628485644","id":"20191106-142432_1665091878","dateCreated":"2019-11-06T14:24:32-0500","dateStarted":"2019-11-06T15:59:29-0500","dateFinished":"2019-11-06T15:59:32-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:19192"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573075893057_1660757470","id":"20191106-163133_332815237","dateCreated":"2019-11-06T16:31:33-0500","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:19193"},{"text":"%md\n\n#### Q4: Generate a daily and a weekly sales table and plot diagrams using Zeppelin built-in plot.\n\ndailyDf = retDf1.groupBy(\"InvoiceDate\").sum(\"amount\")\n\nReadings\n- https://databricks.com/blog/2017/05/08/event-time-aggregation-watermarking-apache-sparks-structured-streaming.html\n- http://blog.madhukaraphatak.com/introduction-to-spark-two-part-5/","user":"anonymous","dateUpdated":"2019-11-07T08:27:21-0500","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.net.SocketException: Broken pipe (Write failed)\n\tat java.net.SocketOutputStream.socketWrite0(Native Method)\n\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:111)\n\tat java.net.SocketOutputStream.write(SocketOutputStream.java:155)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\n\tat org.apache.thrift.transport.TIOStreamTransport.write(TIOStreamTransport.java:145)\n\tat org.apache.thrift.protocol.TBinaryProtocol.writeString(TBinaryProtocol.java:202)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext$RemoteInterpreterContextStandardScheme.write(RemoteInterpreterContext.java:1213)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext$RemoteInterpreterContextStandardScheme.write(RemoteInterpreterContext.java:1074)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext.write(RemoteInterpreterContext.java:956)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$interpret_args$interpret_argsStandardScheme.write(RemoteInterpreterService.java:6781)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$interpret_args$interpret_argsStandardScheme.write(RemoteInterpreterService.java:6704)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$interpret_args.write(RemoteInterpreterService.java:6631)\n\tat org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:63)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.send_interpret(RemoteInterpreterService.java:268)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:257)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:437)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1572989441848_-470826171","id":"20190520-140931_1510736707","dateCreated":"2019-11-05T16:30:41-0500","dateStarted":"2019-11-07T08:27:21-0500","dateFinished":"2019-11-07T08:27:21-0500","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:19194","errorMessage":"java.net.SocketException: Broken pipe (Write failed)\n\tat java.net.SocketOutputStream.socketWrite0(Native Method)\n\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:111)\n\tat java.net.SocketOutputStream.write(SocketOutputStream.java:155)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\n\tat org.apache.thrift.transport.TIOStreamTransport.write(TIOStreamTransport.java:145)\n\tat org.apache.thrift.protocol.TBinaryProtocol.writeString(TBinaryProtocol.java:202)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext$RemoteInterpreterContextStandardScheme.write(RemoteInterpreterContext.java:1213)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext$RemoteInterpreterContextStandardScheme.write(RemoteInterpreterContext.java:1074)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext.write(RemoteInterpreterContext.java:956)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$interpret_args$interpret_argsStandardScheme.write(RemoteInterpreterService.java:6781)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$interpret_args$interpret_argsStandardScheme.write(RemoteInterpreterService.java:6704)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$interpret_args.write(RemoteInterpreterService.java:6631)\n\tat org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:63)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.send_interpret(RemoteInterpreterService.java:268)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:257)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:437)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"},{"text":"val retDf2 = retailDf.selectExpr(\"InvoiceNo AS DD/MM/YYYY\",\"quantity*UnitPrice AS Amount\", \"Country\", \"InvoiceDate\")\n\n\nval dailyDf = retDf2.groupBy(\"InvoiceDate\").count().show()\n\n","user":"anonymous","dateUpdated":"2019-11-06T16:33:42-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.spark.sql.catalyst.parser.ParseException:\nmismatched input '/' expecting <EOF>(line 1, pos 15)\n\n== SQL ==\nInvoiceNo AS DD/MM/YYYY\n---------------^^^\n\n  at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:217)\n  at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:114)\n  at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:48)\n  at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parseExpression(ParseDriver.scala:43)\n  at org.apache.spark.sql.Dataset$$anonfun$selectExpr$1.apply(Dataset.scala:1186)\n  at org.apache.spark.sql.Dataset$$anonfun$selectExpr$1.apply(Dataset.scala:1185)\n  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n  at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n  at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n  at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n  at scala.collection.AbstractTraversable.map(Traversable.scala:104)\n  at org.apache.spark.sql.Dataset.selectExpr(Dataset.scala:1185)\n  ... 75 elided\n"}]},"apps":[],"jobName":"paragraph_1573075057613_1725675245","id":"20191106-161737_1233677377","dateCreated":"2019-11-06T16:17:37-0500","dateStarted":"2019-11-06T16:33:42-0500","dateFinished":"2019-11-06T16:33:43-0500","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:19195"},{"text":"","user":"anonymous","dateUpdated":"2019-11-05T16:30:41-0500","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------------+------------------+\n|              start|       sum(amount)|\n+-------------------+------------------+\n|2010-11-30 19:00:00| 58833.88000000002|\n|2010-12-01 19:00:00| 45666.62999999998|\n|2010-12-02 19:00:00| 46161.11000000004|\n|2010-12-04 19:00:00|          31383.95|\n|2010-12-05 19:00:00|53860.180000000044|\n+-------------------+------------------+\nonly showing top 5 rows\n\ndailySalesDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [start: timestamp, sum(amount): double]\n"}]},"apps":[],"jobName":"paragraph_1572989441848_-1310704205","id":"20190520-181045_1661878813","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19196"},{"text":"%sql\nselect to_date(start), `sum(amount)` from dailySales","user":"anonymous","dateUpdated":"2019-11-07T08:12:59-0500","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/sql","fontSize":9,"results":{"0":{"graph":{"mode":"lineChart","height":326,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"start":"string","sum(amount)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"lineChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"stackedAreaChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"pieChart":{}},"commonSetting":{},"keys":[{"name":"to_date(dailysales.`start`)","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"sum(amount)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"to_date(dailysales.`start`)\tsum(amount)\n2010-11-30\t58833.88000000002\n2010-12-01\t45666.62999999998\n2010-12-02\t46161.11000000004\n2010-12-04\t31383.95\n2010-12-05\t53860.180000000044\n2010-12-06\t45059.05000000006\n2010-12-07\t44189.84\n2010-12-08\t51501.75\n2010-12-09\t58435.29\n2010-12-11\t17240.919999999995\n2010-12-12\t35379.340000000004\n2010-12-13\t42843.29\n2010-12-14\t29443.690000000002\n2010-12-15\t45654.68999999997\n2010-12-16\t46213.84999999999\n2010-12-18\t7517.310000000002\n2010-12-19\t24741.749999999985\n2010-12-20\t47097.93999999999\n2010-12-21\t6134.570000000001\n2010-12-22\t11796.309999999992\n2011-01-03\t14950.479999999998\n2011-01-04\t-1221.4199999999946\n2011-01-05\t37392.73999999998\n2011-01-06\t27233.14\n2011-01-08\t15710.800000000005\n2011-01-09\t24191.63999999999\n2011-01-10\t67817.13000000003\n2011-01-11\t23958.780000000013\n2011-01-12\t20533.54\n2011-01-13\t47377.25999999999\n2011-01-15\t7116.610000000001\n2011-01-16\t29256.000000000025\n2011-01-17\t18680.800000000017\n2011-01-18\t26352.860000000004\n2011-01-19\t19290.35\n2011-01-20\t34822.5\n2011-01-22\t10441.590000000002\n2011-01-23\t25555.619999999995\n2011-01-24\t27971.52000000001\n2011-01-25\t19659.619999999984\n2011-01-26\t20910.789999999994\n2011-01-27\t18749.12\n2011-01-29\t6456.4400000000005\n2011-01-30\t22364.649999999998\n2011-01-31\t29279.909999999996\n2011-02-01\t21048.44999999999\n2011-02-02\t23040.580000000005\n2011-02-03\t27984.819999999996\n2011-02-05\t3457.1100000000006\n2011-02-06\t25525.989999999994\n2011-02-07\t20728.14\n2011-02-08\t16692.58\n2011-02-09\t13203.940000000004\n2011-02-10\t20863.17\n2011-02-12\t5535.4\n2011-02-13\t26222.030000000002\n2011-02-14\t36842.57999999997\n2011-02-15\t26180.69\n2011-02-16\t25996.239999999998\n2011-02-17\t16294.03\n2011-02-19\t9578.89\n2011-02-20\t23807.830000000013\n2011-02-21\t35629.38\n2011-02-22\t26792.76000000001\n2011-02-23\t22761.030000000002\n2011-02-24\t18029.840000000007\n2011-02-26\t9491.050000000001\n2011-02-27\t21753.680000000015\n2011-02-28\t25471.710000000003\n2011-03-01\t18577.879999999994\n2011-03-02\t35487.529999999984\n2011-03-03\t19773.86000000001\n2011-03-05\t9596.23\n2011-03-06\t35833.23\n2011-03-07\t25017.469999999998\n2011-03-08\t21907.120000000003\n2011-03-09\t25431.390000000007\n2011-03-10\t24837.91\n2011-03-12\t4137.62\n2011-03-13\t25864.589999999997\n2011-03-14\t20660.03\n2011-03-15\t21182.639999999992\n2011-03-16\t38081.76999999998\n2011-03-17\t18273.289999999994\n2011-03-19\t21980.640000000003\n2011-03-20\t16370.269999999993\n2011-03-21\t31312.35000000001\n2011-03-22\t24029.070000000003\n2011-03-23\t36897.419999999984\n2011-03-24\t30656.029999999995\n2011-03-26\t8979.980000000001\n2011-03-27\t19207.030000000002\n2011-03-28\t92159.18999999997\n2011-03-29\t31489.250000000004\n2011-03-30\t31004.07999999999\n2011-03-31\t24391.780000000002\n2011-04-02\t6878.1\n2011-04-03\t25073.02000000002\n2011-04-04\t28353.830000000013\n2011-04-05\t17279.34999999999\n2011-04-06\t18373.860000000004\n2011-04-07\t24738.619999999995\n2011-04-09\t9363.880000000001\n2011-04-10\t22110.31000000001\n2011-04-11\t25124.249999999993\n2011-04-12\t23898.2\n2011-04-13\t35295.58000000001\n2011-04-14\t28327.13100000001\n2011-04-16\t13785.77\n2011-04-17\t32185.61000000003\n2011-04-18\t24012.66000000001\n2011-04-19\t28239.389999999996\n2011-04-20\t31198.600000000002\n2011-04-25\t30585.539999999994\n2011-04-26\t25590.559999999998\n2011-04-27\t21241.900000000005\n2011-04-30\t6964.660000000001\n2011-05-02\t19617.860000000015\n2011-05-03\t27462.3\n2011-05-04\t29872.219999999998\n2011-05-05\t35692.439999999995\n2011-05-06\t22.139999999999997\n2011-05-07\t18808.919999999995\n2011-05-08\t26060.430000000008\n2011-05-09\t45564.12000000004\n2011-05-10\t33240.360000000015\n2011-05-11\t58828.48000000002\n2011-05-12\t31827.560000000016\n2011-05-14\t10369.57\n2011-05-15\t26463.989999999987\n2011-05-16\t53850.72000000001\n2011-05-17\t34337.28999999999\n2011-05-18\t34348.74999999998\n2011-05-19\t26256.519999999997\n2011-05-21\t24353.230000000007\n2011-05-22\t30739.55000000001\n2011-05-23\t37028.910000000025\n2011-05-24\t24152.28\n2011-05-25\t33208.59\n2011-05-26\t28232.19000000001\n2011-05-28\t7208.299999999999\n2011-05-30\t21967.959999999995\n2011-05-31\t20191.2\n2011-06-01\t32502.01\n2011-06-02\t16750.999999999996\n2011-06-04\t25520.35000000001\n2011-06-05\t16791.390000000003\n2011-06-06\t37644.30000000001\n2011-06-07\t42940.90999999999\n2011-06-08\t45165.78999999997\n2011-06-09\t22890.620000000017\n2011-06-11\t12483.86\n2011-06-12\t20372.929999999997\n2011-06-13\t40211.930000000015\n2011-06-14\t46139.18000000001\n2011-06-15\t34131.73000000002\n2011-06-16\t20800.72\n2011-06-18\t22360.010000000002\n2011-06-19\t33493.39999999999\n2011-06-20\t22730.00999999999\n2011-06-21\t21794.940000000002\n2011-06-22\t24273.31\n2011-06-23\t8619.879999999996\n2011-06-25\t6398.239999999998\n2011-06-26\t16823.860000000008\n2011-06-27\t34704.64\n2011-06-28\t21775.429999999997\n2011-06-29\t43630.69000000001\n2011-06-30\t13375.68\n2011-07-02\t5977.140000000001\n2011-07-03\t44154.75000000001\n2011-07-04\t40334.969999999994\n2011-07-05\t26279.58\n2011-07-06\t31104.02000000001\n2011-07-07\t27093.780000000002\n2011-07-09\t5692.070000000001\n2011-07-10\t22429.530000000002\n2011-07-11\t25892.04000000001\n2011-07-12\t11612.050000000007\n2011-07-13\t31803.53000000001\n2011-07-14\t15251.360000000006\n2011-07-16\t17174.659999999993\n2011-07-17\t28443.270000000008\n2011-07-18\t49316.78000000001\n2011-07-19\t27305.41000000001\n2011-07-20\t30957.06999999999\n2011-07-21\t20015.230000000003\n2011-07-23\t26476.2\n2011-07-24\t26687.65\n2011-07-25\t22898.781\n2011-07-26\t25568.450000000004\n2011-07-27\t55706.880000000005\n2011-07-28\t18094.21\n2011-07-30\t33486.36000000001\n2011-07-31\t21362.839999999997\n2011-08-01\t14947.27000000001\n2011-08-02\t27519.240000000013\n2011-08-03\t60778.32999999999\n2011-08-04\t21548.619999999995\n2011-08-06\t7464.120000000002\n2011-08-07\t19987.14999999999\n2011-08-08\t26623.199999999993\n2011-08-09\t27474.219999999998\n2011-08-10\t72132.79\n2011-08-11\t10049.48000000001\n2011-08-13\t5150.18\n2011-08-14\t17617.239999999998\n2011-08-15\t19103.710000000014\n2011-08-16\t36360.72000000001\n2011-08-17\t66016.51\n2011-08-18\t17489.199999999997\n2011-08-20\t14549.209999999997\n2011-08-21\t27978.41\n2011-08-22\t25756.299999999996\n2011-08-23\t37074.89999999998\n2011-08-24\t22458.879999999994\n2011-08-25\t25550.229999999985\n2011-08-27\t10784.78\n2011-08-29\t31640.90000000001\n2011-08-30\t16118.000000000007\n2011-08-31\t37296.6\n2011-09-01\t41745.06999999999\n2011-09-03\t17018.49000000001\n2011-09-04\t36844.03999999999\n2011-09-05\t28052.62\n2011-09-06\t34125.65000000001\n2011-09-07\t26708.00000000002\n2011-09-08\t29317.69000000001\n2011-09-10\t35465.47000000001\n2011-09-11\t29039.31000000001\n2011-09-12\t54828.44999999999\n2011-09-13\t23360.659999999996\n2011-09-14\t62943.81\n2011-09-15\t25858.060000000005\n2011-09-17\t19537.170000000002\n2011-09-18\t46212.21000000001\n2011-09-19\t109286.20999999999\n2011-09-20\t42944.070000000014\n2011-09-21\t57076.82999999999\n2011-09-22\t39426.479999999996\n2011-09-24\t31210.920999999995\n2011-09-25\t28642.271000000008\n2011-09-26\t35752.160000000025\n2011-09-27\t43383.03999999999\n2011-09-28\t43464.32999999999\n2011-09-29\t43992.85000000002\n2011-10-01\t11623.579999999996\n2011-10-02\t64214.78000000001\n2011-10-03\t48240.84\n2011-10-04\t75244.43000000002\n2011-10-05\t58049.620000000024\n2011-10-06\t44794.680000000015\n2011-10-08\t11922.240000000003\n2011-10-09\t44265.890000000036\n2011-10-10\t38267.75000000002\n2011-10-11\t29302.850000000013\n2011-10-12\t37067.16999999998\n2011-10-13\t35225.53999999998\n2011-10-15\t21605.44000000001\n2011-10-16\t47064.140000000036\n2011-10-17\t44637.84000000001\n2011-10-18\t36788.5\n2011-10-19\t60793.13999999999\n2011-10-20\t62961.26000000003\n2011-10-22\t12302.41\n2011-10-23\t38407.72000000002\n2011-10-24\t40807.49000000002\n2011-10-25\t37842.08000000001\n2011-10-26\t46019.69999999998\n2011-10-27\t41019.92000000003\n2011-10-29\t34545.28000000002\n2011-10-30\t48475.44999999994\n2011-10-31\t28741.54999999999\n2011-11-01\t48753.80000000003\n2011-11-02\t62816.55\n2011-11-03\t60081.76000000001\n2011-11-05\t42912.399999999994\n2011-11-06\t70001.07999999996\n2011-11-07\t56647.66\n2011-11-08\t62599.430000000015\n2011-11-09\t66605.45000000004\n2011-11-10\t57186.30000000005\n2011-11-12\t33740.00999999998\n2011-11-13\t112141.10999999997\n2011-11-14\t60594.23000000001\n2011-11-15\t64408.700000000026\n2011-11-16\t57904.93000000001\n2011-11-17\t50456.590000000004\n2011-11-19\t34902.01\n2011-11-20\t48302.50000000006\n2011-11-21\t62307.31999999999\n2011-11-22\t78480.69999999998\n2011-11-23\t47529.51\n2011-11-24\t51247.10000000001\n2011-11-26\t20571.500000000004\n2011-11-27\t55442.02000000001\n2011-11-28\t72219.20000000006\n2011-11-29\t59150.98000000004\n2011-11-30\t49852.26999999997\n2011-12-01\t58644.74000000001\n2011-12-03\t24565.779999999984\n2011-12-04\t57751.32000000003\n2011-12-05\t54228.37000000003\n2011-12-06\t75076.22\n2011-12-07\t80405.06999999999\n2011-12-08\t33144.23999999999\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1572989441848_-1909940133","id":"20190520-140933_785400989","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19197"},{"text":"","user":"anonymous","dateUpdated":"2019-11-05T16:30:41-0500","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------------+------------------+\n|              start|       sum(amount)|\n+-------------------+------------------+\n|2010-11-24 19:00:00| 58833.88000000002|\n|2010-12-01 19:00:00|         266320.76|\n|2010-12-08 19:00:00|234844.27999999997|\n|2010-12-15 19:00:00|177360.10999999993|\n|2010-12-22 19:00:00|11796.309999999992|\n+-------------------+------------------+\nonly showing top 5 rows\n\nweeklySalesDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [start: timestamp, sum(amount): double]\n"}]},"apps":[],"jobName":"paragraph_1572989441849_1895253585","id":"20190520-140933_428817963","dateCreated":"2019-11-05T16:30:41-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:19198"}],"name":"DataFrame_pub","id":"2ETPZ8RPS","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}